# -*- coding: utf-8 -*-
"""chat_labeler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T8gO2SR8spXcSUDopnw_wdIw4RaBbmSw
"""

!pip install textblob
!python -m textblob.download_corpora
!pip install vaderSentiment
import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
import sklearn as sk
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer

from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

data = pd.read_pickle('admiralbulldog.pkl')
# data['toxic'] = None
# data.to_pickle('admiralbulldog.pkl')
data.head()

data['toxic'].describe()

# data['toxic'] = data['toxic'][0:400] + [None for i in range(len(data)-400)]
# num_labeled = len(data[data['toxic'] != None])

for j, row in data.iterrows():
    # if row['toxic'] is None and '@admiral' in row['body']:
    # if row['toxic'] is None and 'fuck' in row['body'].lower():
    if row['toxic'] is None and ' ' in row['body'].lower():
        x = input(row['body'] + ': ')
        if x is 'q':
          break
        data.at[j, 'toxic'] = 1 if x is 't' else 0
        num_labeled += 1

num_labeled = len(data[data['toxic'].isin([0,1])])
print(f'labeled data points: {num_labeled}')
t_count = len(data[data['toxic'] == True])
print(f'{t_count} of those are likely toxic')
data.to_pickle('admiralbulldog.pkl')

max_show = 20
toxic_words = []
okay_words = []

for i, row in data[data['toxic'] == True].iterrows():
    sentence = row['body'].lower()
    for word in sentence.split(' '):
        if '@' not in word:
            toxic_words.append(word)

for i, row in data[data['toxic'] == False].iterrows():
    sentence = row['body'].lower()
    for word in sentence.split(' '):
        if '@' not in word:
            toxic_words.append(word)

t_counts = Counter(toxic_words)
t_labels, t_values = zip(*t_counts.items())

ind_sort = np.argsort(t_values)[::-1]

t_labels = np.array(t_labels)[ind_sort][:max_show]
t_values = np.array(t_values)[ind_sort][:max_show]

indexes = np.arange(len(t_labels))

bar_width = 0.35

plt.bar(indexes, t_values)

plt.xticks(indexes + bar_width, t_labels, rotation=90)
plt.title('Bag of Words for Toxic Messages')
plt.show()

test = [
        'HOY ADMIRAL BOBO WASHED UP IDIOT',
        '@admiralbulldog but you are bald and i have hairs LULW',
        '@admiralbulldog qualify for last place again LUL',
        'shut up chat u fucks',
        'Dude how do you skip eye of the tiger for this garbage song',
]
for s in test:
    blob = TextBlob(s)
    print(blob)
    print(blob.sentiment)
    print()

analyzer = SentimentIntensityAnalyzer()
for s in test:
    print(s)
    print(analyzer.polarity_scores(s))
    print()

def remove_punctuation(text):
    return "".join(u for u in text if u not in ("?", ".", ";", ":",  "!",'"', '@'))

clean_data = data[data['toxic'].isin([0,1])]
clean_data['text'] = clean_data.apply(lambda row: remove_punctuation(row['body']), axis=1)
clean_data = clean_data.drop(['body', 'channel_id', 'commenter_id', 'commenter_type', 'created_at', 'fragments',	'offset', 'updated_at', 'video_id'], axis=1)

print(len(clean_data))
clean_data.head()

X_train, X_test, y_train, y_test = train_test_split(clean_data['text'], clean_data['toxic'], test_size=0.15)

# display(clean_data['toxic'].describe())
# display(clean_data)

y_train = y_train.astype('int')
y_test = y_test.astype('int')

vectorizer = CountVectorizer(token_pattern=r'\b\w+\b')

train_matrix = vectorizer.fit_transform(X_train)
test_matrix = vectorizer.transform(X_test)

lr = LogisticRegression()
lr.fit(train_matrix, y_train)
pred = lr.predict(test_matrix)

result = X_test
result['class'] = pred

sk.metrics.f1_score(y_test, pred)

